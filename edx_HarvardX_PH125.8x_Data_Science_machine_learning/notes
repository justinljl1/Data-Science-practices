### Section 1
### Section 2
## read zip code
## predict sex using height
# quantitative definition of 'better'
# split data into training (to develop algorithm) and test (evaluate algorithm) sets

library(caret)
library(dslabs)
data(heights)

y <- heights$sex
x <- heights$height

set.seed(2025)
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
test_set <- heights[test_index, ]
train_set <- heights[-test_index, ]

# predict by guesssing
y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE) %>% 
  factor(levels = levels(test_set$sex))
mean(y_hat == test_set$sex)

# predict with height cutoff
y_hat <- ifelse(x > 62, "Male", "Female") %>% factor(levels = levels(test_set$sex))
mean(y == y_hat)

# testing cutoffs for better prediction
cutoff <- seq(61, 70)
accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  mean(y_hat == train_set$sex)
})
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line() 
max(accuracy)

best_cutoff <- cutoff[which.max(accuracy)]
best_cutoff

y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)


y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)


# bias, overall accuracy, sensitivity & specificity
table(predicted = y_hat, actual = test_set$sex)

# further optimizing algorithm ('better' is defined as higher F1-score or harmonic average of precision and recall)
# precision/ specificity: TP/(TP+FP)
# recall/ sensitivity: true positive rate; TP/(TP+FN)

cutoff <- seq(61, 70)
F_1 <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  F_meas(data = y_hat, reference = factor(train_set$sex))
})

data.frame(cutoff, F_1) %>% 
  ggplot(aes(cutoff, F_1)) + 
  geom_point() + 
  geom_line()

max(F_1)

best_cutoff_2 <- cutoff[which.max(F_1)]
best_cutoff_2

y_hat <- ifelse(test_set$height > best_cutoff_2, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
sensitivity(data = y_hat, reference = test_set$sex)
specificity(data = y_hat, reference = test_set$sex)

p <- 0.9
n <- length(test_index)
y_hat <- sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
  factor(levels = levels(test_set$sex))
mean(y_hat == test_set$sex)

# ROC curve
probs <- seq(0, 1, length.out = 10)
guessing <- map_df(probs, function(p){
  y_hat <- 
    sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guessing",
       FPR = 1 - specificity(y_hat, test_set$sex),
       TPR = sensitivity(y_hat, test_set$sex))
})
guessing %>% qplot(FPR, TPR, data =., xlab = "1 - Specificity", ylab = "Sensitivity")

cutoffs <- c(50, seq(60, 75), 80)
height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
})

# plot both curves together
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(FPR, TPR, color = method)) +
  geom_line() +
  geom_point() +
  xlab("1 - Specificity") +
  ylab("Sensitivity")

library(ggrepel)
map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        cutoff = x, 
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
}) %>%
  ggplot(aes(FPR, TPR, label = cutoff)) +
  geom_line() +
  geom_point() +
  geom_text_repel(nudge_x = 0.01, nudge_y = -0.01)

# plot precision against recall
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), 
                  replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guess",
    recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE, 
                  prob=c(p, 1-p)) %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Guess",
    recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()


## loss function to refine algorithm for continuous and categorical outcome
#
prop.table(table(dat[dat$type =="online",]$sex))

#
dat$predicted_sex <- ifelse(dat$type == "inclass", "Female", "Male")
mean(dat$sex == dat$predicted_sex)

#
table(ifelse(x == "inclass", "Female", "Male"), y)

#
y_hat <- ifelse(x == "inclass", "Female", "Male") %>% 
  factor(levels = levels(y))
sensitivity(data = y_hat, reference = as.factor(y))

#
prop.table(table(dat$sex))

##
library(caret)
data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
levels(iris$Species) <- droplevels(iris$Species)

set.seed(1)
test_index <- createDataPartition(iris$Species, times=1, p=0.5, list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]

max_F1_scores <- numeric(4)
best_cutoffs <- numeric(4)
for (i in 1:4){
  cutoff <- seq(min(train[,i]), max(train[,i]), by=0.1)
  temp <- map_dbl(cutoff, function(x){
    y_hat <- ifelse(train[,i] > x, "virginica", "versicolor") %>% 
      factor(levels = levels(train$Species))
    accuracy <- mean(y_hat == train$Species)
  })
  max_F1_scores[i] <- max(temp)
  best_cutoffs[i] <- cutoff[which.max(max_F1_scores)]
}

##
y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)

## 
cutoff3 <- seq(min(train[,3]), max(train[,3]), by=0.1)
cutoff4 <- seq(min(train[,4]), max(train[,4]), by=0.1)
cutoff <- expand.grid(x=cutoff3, y=cutoff4)

temp <- pmap_dbl(cutoff, function(x,y){
  y_hat <- ifelse(train[,3] > x & train[,4] > y, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  
  mean(y_hat == train$Species)
})

max_F1_scores <- max(temp)
best_cutoffs <- cutoff[which.max(temp),]

y_hat <- ifelse(test$Petal.Length >3 & test$Petal.Width > 1.7, "virginica", "versicolor")
y_hat <- factor(y_hat)
test$Species <- droplevels(test$Species)
mean(y_hat == test$Species)
